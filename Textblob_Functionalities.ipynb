{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aravindb212/NLP/blob/main/Textblob_Functionalities.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d869eae7",
      "metadata": {
        "id": "d869eae7"
      },
      "source": [
        "## What is Textblob\n",
        "\n",
        "* Textblob is an open-source python library used to perform NLP activities like Lemmatization, Stemming, Tokenization, Noun Phrase Extraction, POS Tagging, N-Grams, Sentiment Analysis.\n",
        "\n",
        "* It is faster than NLTK, however it does not provide the functionalities like vectorization, dependency parsing.\n",
        "\n",
        "* Text Classification, Sentiment Analysis can be performed using Textblob.\n",
        "* Official Link to Textblob is: https://textblob.readthedocs.io/en/dev/\n",
        "\n",
        "* Installation: pip install textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ea0c543",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ea0c543",
        "outputId": "20332136-0ee6-47be-e915-6a71fc93f925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "### Install Textblob\n",
        "!pip install nltk\n",
        "!pip install textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51aa56b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51aa56b6",
        "outputId": "ae6f7469-0169-4611-a99e-95b3c5b09da4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('popular')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5213c0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5213c0b",
        "outputId": "6afc2968-423f-4d85-d0b6-1855ca672d50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a807ca3",
      "metadata": {
        "id": "0a807ca3"
      },
      "source": [
        "### Functionalities of Textblob\n",
        "* Language Detection\n",
        "* Word Correction\n",
        "* Word Count\n",
        "* Phrase Extraction\n",
        "* POS Tagging\n",
        "* Tokenization\n",
        "* Plularization of words using Textblob\n",
        "* Lemmatization using Textblob\n",
        "* n-gram in Textblob"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1059517a",
      "metadata": {
        "id": "1059517a"
      },
      "source": [
        "#### Language Detection\n",
        "* With the help of Google Translate, Textblob detects the language of input text.\n",
        "* Textblob is also able to translate text from one language to another language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "f9fdb42d",
      "metadata": {
        "id": "f9fdb42d"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "blob = TextBlob(\"Hey John, How are You\")\n",
        "\n",
        "print(\"Detected Language is:\",blob.detect_language())\n",
        "\n",
        "print(\"Input text in Spanish:\",blob.translate(to='es'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8710e0b7",
      "metadata": {
        "id": "8710e0b7"
      },
      "source": [
        "### Note:\n",
        "Since Google has made some changes into its API and Textblob is using the older API, as a result you may get 404 error. To avoide this, change the url given in translate.py under your environment.\n",
        "\n",
        "\n",
        "updated url link is:\n",
        "url = \"http://translate.google.com/translate_a/t?client=te&format=html&dt=bd&dt=ex&dt=ld&dt=md&dt=qca&dt=rw&dt=rm&dt=ss&dt=t&dt=at&ie=UTF-8&oe=UTF-8&otf=2&ssel=0&tsel=0&kc=1\"\n",
        "\n",
        "\n",
        "Location of translate.py file: C:\\Users\\<user name>\\Anaconda3\\envs\\Rython\\Lib\\site-packages\\textblob\\translate.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00fe5f92",
      "metadata": {
        "id": "00fe5f92"
      },
      "source": [
        "#### Spelling Correction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "adf80d3b",
      "metadata": {
        "id": "adf80d3b"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n",
        "text=\"\"\" ABCD Corp alays values\n",
        " ttheir employees!!!\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "0757e15d",
      "metadata": {
        "id": "0757e15d",
        "outputId": "98cc9109-b3c4-4b66-c9aa-75425f38bdc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ABCD Corp alays values ttheir employees!!!\n"
          ]
        }
      ],
      "source": [
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "fe50b2bf",
      "metadata": {
        "id": "fe50b2bf"
      },
      "outputs": [],
      "source": [
        "blob=TextBlob(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "bddbd582",
      "metadata": {
        "id": "bddbd582",
        "outputId": "e70a8f29-5bf6-45bd-c768-e6526d93ce07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\" ABCD Corp alays values ttheir employees!!!\")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "blob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e0941e0b",
      "metadata": {
        "id": "e0941e0b",
        "outputId": "057f4aef-5130-43b6-f0ea-0f580a0286c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\" ABCD For always values their employees!!!\")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "blob.correct()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "29eab446",
      "metadata": {
        "id": "29eab446",
        "outputId": "e1e612c3-70b7-44b1-b51d-3c21ab38af2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\"has\")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "TextBlob('hasss').correct()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "049a9342",
      "metadata": {
        "id": "049a9342",
        "outputId": "daccc467-d171-4126-8eed-f8c4f5f34d03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\"or\")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "### Sometimes it failsas well\n",
        "TextBlob('ur').correct()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fe3704f",
      "metadata": {
        "id": "9fe3704f"
      },
      "source": [
        "### Word Count\n",
        "With the help of word count, we can count the frequency of words or a noun phrase in a given sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "f1169c9d",
      "metadata": {
        "id": "f1169c9d"
      },
      "outputs": [],
      "source": [
        "text=\"Sentiment Analysis is a process by which we can find the sentiment of a text. Sentiment can be Positive, Negative or Neutral\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "ad31d646",
      "metadata": {
        "id": "ad31d646"
      },
      "outputs": [],
      "source": [
        "blob=TextBlob(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "5b830875",
      "metadata": {
        "id": "5b830875",
        "outputId": "13ca0c3d-c25e-4460-815a-e1dd42124ce2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "blob.word_counts[\"analysis\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "9daa2972",
      "metadata": {
        "id": "9daa2972",
        "outputId": "27c94570-f19e-4e30-ceca-2297312c63d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "blob.word_counts[\"Sentiment\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "1fbf1a59",
      "metadata": {
        "id": "1fbf1a59",
        "outputId": "408dea0c-c5a2-4e5c-a29b-90789b6c3b39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "blob.word_counts[\"sentiment\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "4a39c4bc",
      "metadata": {
        "id": "4a39c4bc",
        "outputId": "cc28397e-42b8-4464-b5cf-f6027b4308cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "blob.word_counts[\"Analysis\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3582855",
      "metadata": {
        "id": "c3582855"
      },
      "source": [
        "### POS Tagging\n",
        "With the help of tags function of textblob, we can get tag each words of a sentence with a tag that can be either noun, pronoun, verb, adverb, adjective and more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "680e50c0",
      "metadata": {
        "id": "680e50c0",
        "outputId": "972a27a9-1754-427b-a81c-bdb596f39987",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('My', 'PRP$'), ('name', 'NN'), ('is', 'VBZ'), ('Adam', 'NNP'), ('I', 'PRP'), ('like', 'VBP'), ('to', 'TO'), ('read', 'VB'), ('about', 'IN'), ('NLP', 'NNP'), ('I', 'PRP'), ('work', 'VBP'), ('at', 'IN'), ('ABCD', 'NNP'), ('Corp', 'NNP')]\n"
          ]
        }
      ],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "text = TextBlob(\"My name is Adam. I like to read about NLP. I work at ABCD Corp.\")\n",
        "print(text.tags)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "18a7c0ba",
      "metadata": {
        "id": "18a7c0ba",
        "outputId": "836aeb3e-5302-476d-eaca-9abca51bb576",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('My', 'PRP$')\n",
            "('name', 'NN')\n",
            "('is', 'VBZ')\n",
            "('Adam', 'NNP')\n",
            "('I', 'PRP')\n",
            "('like', 'VBP')\n",
            "('to', 'TO')\n",
            "('read', 'VB')\n",
            "('about', 'IN')\n",
            "('NLP', 'NNP')\n",
            "('I', 'PRP')\n",
            "('work', 'VBP')\n",
            "('at', 'IN')\n",
            "('ABCD', 'NNP')\n",
            "('Corp', 'NNP')\n"
          ]
        }
      ],
      "source": [
        "new_tuple=[]\n",
        "for i in text.tags:\n",
        "    print(i)\n",
        "    if 'VBP' not in i[1]:\n",
        "        new_tuple.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "f2a4260c",
      "metadata": {
        "id": "f2a4260c",
        "outputId": "48ee4ce3-fee7-4562-e1ce-618c0b85fd2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('My', 'PRP$'),\n",
              " ('name', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('Adam', 'NNP'),\n",
              " ('I', 'PRP'),\n",
              " ('to', 'TO'),\n",
              " ('read', 'VB'),\n",
              " ('about', 'IN'),\n",
              " ('NLP', 'NNP'),\n",
              " ('I', 'PRP'),\n",
              " ('at', 'IN'),\n",
              " ('ABCD', 'NNP'),\n",
              " ('Corp', 'NNP')]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "new_tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "a2be7d14",
      "metadata": {
        "id": "a2be7d14"
      },
      "outputs": [],
      "source": [
        "value=''\n",
        "for i in new_tuple:\n",
        "    value=value+\" \" + \"\".join(i[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "7d3a2219",
      "metadata": {
        "id": "7d3a2219",
        "outputId": "8d9731da-c0b7-4e9f-e452-0c1f4ba5a80b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' My name is Adam I to read about NLP I at ABCD Corp'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "value"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6570dce4",
      "metadata": {
        "id": "6570dce4"
      },
      "source": [
        "#### Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ee75c7a",
      "metadata": {
        "id": "3ee75c7a"
      },
      "source": [
        "* Corpus (or corpora in plural) - Corpus is nothing but a collection of text data. The text maybe in one language or maybe a combination of two or more.\n",
        "\n",
        "* Token - The term \"Token\" is nothing but the total number of words in a text, corpus etc, regardless of their freuqncy of occurrence in the text. Tokens are nothing but a string of contiguous characters which either lies between the two spaces or it lies between a space and punctuation. For Example: Suppose you have the following string : \"abc_123_defg\", if you split it on basis of underscores \"_\" you obtained three tokens : \"abc\", \"123\" and \"defg\".\n",
        "\n",
        "**What is tokenization?**\n",
        "\n",
        "Tokenization is a process of splitting the sentence or corpus into its smalles unit i.e. \"Tokens\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "b9a0bd4d",
      "metadata": {
        "id": "b9a0bd4d"
      },
      "outputs": [],
      "source": [
        "text=\"\"\"\n",
        "R is a comprehensive statistical and graphical programming language, which is fast gaining popularity among data analysts. It is free and runs on a variety of platforms, including Windows, Unix, and macOS. It provides an unparalleled platform for programming new statistical methods in an easy and straightforward manner.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "d13f6259",
      "metadata": {
        "id": "d13f6259"
      },
      "outputs": [],
      "source": [
        "blob_object = TextBlob(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "b60b83f3",
      "metadata": {
        "id": "b60b83f3"
      },
      "outputs": [],
      "source": [
        "# Word tokenization of the sample corpus\n",
        "corpus_words = blob_object.words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "a87be64b",
      "metadata": {
        "id": "a87be64b",
        "outputId": "71210e1a-e8d1-4fab-e2a1-c83604a1c546",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['R', 'is', 'a', 'comprehensive', 'statistical', 'and', 'graphical', 'programming', 'language', 'which', 'is', 'fast', 'gaining', 'popularity', 'among', 'data', 'analysts', 'It', 'is', 'free', 'and', 'runs', 'on', 'a', 'variety', 'of', 'platforms', 'including', 'Windows', 'Unix', 'and', 'macOS', 'It', 'provides', 'an', 'unparalleled', 'platform', 'for', 'programming', 'new', 'statistical', 'methods', 'in', 'an', 'easy', 'and', 'straightforward', 'manner'])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "corpus_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "45a3f96b",
      "metadata": {
        "id": "45a3f96b",
        "outputId": "3055be3a-4515-40d0-b056-334ad421f8e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n"
          ]
        }
      ],
      "source": [
        "print(len(corpus_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "4fd6bab8",
      "metadata": {
        "id": "4fd6bab8"
      },
      "outputs": [],
      "source": [
        "corpus_sentences= blob_object.sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "5528532a",
      "metadata": {
        "id": "5528532a",
        "outputId": "ff45fb12-3877-4ad3-be0a-9d5ca615ea6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Sentence(\"\n",
              " R is a comprehensive statistical and graphical programming language, which is fast gaining popularity among data analysts.\"),\n",
              " Sentence(\"It is free and runs on a variety of platforms, including Windows, Unix, and macOS.\"),\n",
              " Sentence(\"It provides an unparalleled platform for programming new statistical methods in an easy and straightforward manner.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "corpus_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b598ee43",
      "metadata": {
        "id": "b598ee43",
        "outputId": "88c63c67-4636-4e92-cc6e-832c617f7c88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        }
      ],
      "source": [
        "print(len(corpus_sentences))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f396561",
      "metadata": {
        "id": "5f396561"
      },
      "source": [
        "#### Pluralization of words using Textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "547f7446",
      "metadata": {
        "id": "547f7446",
        "outputId": "88fb2658-dfcd-4e2e-9d69-d1d807cd7aa0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Platforms'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from textblob import Word\n",
        "w = Word('Platform')\n",
        "w.pluralize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "bdf342db",
      "metadata": {
        "id": "bdf342db",
        "outputId": "9f044a7e-5349-4a6a-87f5-0715572ac371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Platformss'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "from textblob import Word\n",
        "w = Word('Platforms')\n",
        "w.pluralize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "e6343f1f",
      "metadata": {
        "id": "e6343f1f",
        "outputId": "5884b7a5-e3d1-4da1-f6ae-bd48cb2fbf96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "platforms\n",
            "sciences\n",
            "communities\n",
            "etcs\n"
          ]
        }
      ],
      "source": [
        "blob = TextBlob(\"Great Learning is a great platform to learn data science. \\n It helps community through blogs, Youtube, GLA,etc.\")\n",
        "for word,pos in blob.tags:\n",
        "    if pos == 'NN':\n",
        "        print (word.pluralize())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fc3cb03",
      "metadata": {
        "id": "3fc3cb03"
      },
      "source": [
        "#### Lemmatization using Textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9d5ddb2",
      "metadata": {
        "id": "f9d5ddb2",
        "outputId": "e3621c88-e9c3-4d51-ca6b-cff9dd365e4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ORIGINAL: Great | LEMMA: Great | STEM: great\n",
            "ORIGINAL: Learning | LEMMA: Learning | STEM: learn\n",
            "ORIGINAL: is | LEMMA: is | STEM: is\n",
            "ORIGINAL: a | LEMMA: a | STEM: a\n",
            "ORIGINAL: great | LEMMA: great | STEM: great\n",
            "ORIGINAL: platform | LEMMA: platform | STEM: platform\n",
            "ORIGINAL: to | LEMMA: to | STEM: to\n",
            "ORIGINAL: learn | LEMMA: learn | STEM: learn\n",
            "ORIGINAL: data | LEMMA: data | STEM: data\n",
            "ORIGINAL: science | LEMMA: science | STEM: scienc\n",
            "ORIGINAL: It | LEMMA: It | STEM: it\n",
            "ORIGINAL: helps | LEMMA: help | STEM: help\n",
            "ORIGINAL: community | LEMMA: community | STEM: commun\n",
            "ORIGINAL: through | LEMMA: through | STEM: through\n",
            "ORIGINAL: blogs | LEMMA: blog | STEM: blog\n",
            "ORIGINAL: Youtube | LEMMA: Youtube | STEM: youtub\n",
            "ORIGINAL: GLA | LEMMA: GLA | STEM: gla\n",
            "ORIGINAL: etc | LEMMA: etc | STEM: etc\n"
          ]
        }
      ],
      "source": [
        "blob = TextBlob(\"Great Learning is a great platform to learn data science. \\n It helps community through blogs, Youtube, GLA,etc.\")\n",
        "words = blob.words\n",
        "\n",
        "for word in words:\n",
        "    print(\"ORIGINAL:\", word, \"| LEMMA:\", word.lemmatize(), \"| STEM:\", word.stem())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "1fd4a8bb",
      "metadata": {
        "id": "1fd4a8bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6eec00da-c4ce-4e38-c8c2-e7a48a1e96a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'learning'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "w = Word('learning')\n",
        "w.lemmatize(\"n\") ## v here represents verb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "8d08a8c4",
      "metadata": {
        "id": "8d08a8c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ba5d13c0-857d-48e4-f046-0c9c941402ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'learn'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "w = Word('learning')\n",
        "w.lemmatize(\"v\") ## v here represents verb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "e11b2075",
      "metadata": {
        "id": "e11b2075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c10740db-905b-40fc-d3bb-fcc71a0c63ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'people'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "w = Word('peoples')\n",
        "w.lemmatize(\"n\") ## v here represents verb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01024e7c",
      "metadata": {
        "id": "01024e7c"
      },
      "source": [
        "#### n-gram in Textblob\n",
        "\n",
        "An N-gram is an N-token sequence of words: a 2-gram (more commonly called a bigram) is a two-word sequence of words like “really good”, “not good”, or “your homework”, and a 3-gram (more commonly called a trigram) is a three-word sequence of words like “not at all”, or “turn off light”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "fad2e55a",
      "metadata": {
        "id": "fad2e55a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17f480e7-50d9-4268-b840-46f6f926d526"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\"Great Learning is a great platform to learn data science. \n",
              " It helps community through blogs, Youtube, GLA,etc.\")"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "blob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "7fbe2828",
      "metadata": {
        "id": "7fbe2828",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67de9d12-451d-4567-c64a-3d2e56dd6252"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordList(['Great']),\n",
              " WordList(['Learning']),\n",
              " WordList(['is']),\n",
              " WordList(['a']),\n",
              " WordList(['great']),\n",
              " WordList(['platform']),\n",
              " WordList(['to']),\n",
              " WordList(['learn']),\n",
              " WordList(['data']),\n",
              " WordList(['science']),\n",
              " WordList(['It']),\n",
              " WordList(['helps']),\n",
              " WordList(['community']),\n",
              " WordList(['through']),\n",
              " WordList(['blogs']),\n",
              " WordList(['Youtube']),\n",
              " WordList(['GLA']),\n",
              " WordList(['etc'])]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "blob.ngrams(n=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "67a47ee8",
      "metadata": {
        "id": "67a47ee8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2e674ff-62d8-4871-a80b-8bc27704feeb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordList(['Great', 'Learning']),\n",
              " WordList(['Learning', 'is']),\n",
              " WordList(['is', 'a']),\n",
              " WordList(['a', 'great']),\n",
              " WordList(['great', 'platform']),\n",
              " WordList(['platform', 'to']),\n",
              " WordList(['to', 'learn']),\n",
              " WordList(['learn', 'data']),\n",
              " WordList(['data', 'science']),\n",
              " WordList(['science', 'It']),\n",
              " WordList(['It', 'helps']),\n",
              " WordList(['helps', 'community']),\n",
              " WordList(['community', 'through']),\n",
              " WordList(['through', 'blogs']),\n",
              " WordList(['blogs', 'Youtube']),\n",
              " WordList(['Youtube', 'GLA']),\n",
              " WordList(['GLA', 'etc'])]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "blob.ngrams(n=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3346e17e",
      "metadata": {
        "id": "3346e17e"
      },
      "outputs": [],
      "source": [
        "blob.ngrams(n=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "e22ce261",
      "metadata": {
        "id": "e22ce261",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be376069-c2be-41aa-e1c2-10b6b6ebdc20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordList(['Great', 'Learning', 'is', 'a']),\n",
              " WordList(['Learning', 'is', 'a', 'great']),\n",
              " WordList(['is', 'a', 'great', 'platform']),\n",
              " WordList(['a', 'great', 'platform', 'to']),\n",
              " WordList(['great', 'platform', 'to', 'learn']),\n",
              " WordList(['platform', 'to', 'learn', 'data']),\n",
              " WordList(['to', 'learn', 'data', 'science']),\n",
              " WordList(['learn', 'data', 'science', 'It']),\n",
              " WordList(['data', 'science', 'It', 'helps']),\n",
              " WordList(['science', 'It', 'helps', 'community']),\n",
              " WordList(['It', 'helps', 'community', 'through']),\n",
              " WordList(['helps', 'community', 'through', 'blogs']),\n",
              " WordList(['community', 'through', 'blogs', 'Youtube']),\n",
              " WordList(['through', 'blogs', 'Youtube', 'GLA']),\n",
              " WordList(['blogs', 'Youtube', 'GLA', 'etc'])]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "blob.ngrams(n=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4679995b",
      "metadata": {
        "id": "4679995b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}